<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- sidebar iframe generated using mdBook

        This is a frame, and not included directly in the page, to control the total size of the
        book. The TOC contains an entry for each page, so if each page includes a copy of the TOC,
        the total size of the page becomes O(n**2).

        The frame is only used as a fallback when JS is turned off. When it's on, the sidebar is
        instead added to the main page by `toc.js` instead. The JavaScript mode is better
        because, when running in a `file:///` URL, the iframed page would not be Same-Origin as
        the rest of the page, so the sidebar and the main page theme would fall out of sync.
        -->
        <meta charset="UTF-8">
        <meta name="robots" content="noindex">
        <!-- Custom HTML head -->
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../_common/mdbook-ai-pocket-reference.css">
    </head>
    <body class="sidebar-iframe-inner">
        <ol class="chapter"><li class="chapter-item expanded affix "><div>Awesome High-Performance AI Compute</div></li><li class="chapter-item expanded affix "><li class="spacer"></li><li class="chapter-item expanded affix "><a href="index.html" target="_parent">Introduction</a></li><li class="chapter-item expanded affix "><li class="part-title">High-Performance AI Computing</li><li class="chapter-item expanded "><div><strong aria-hidden="true">1.</strong> Parallel Computing</div></li><li class="chapter-item expanded "><a href="cuda/index.html" target="_parent"><strong aria-hidden="true">2.</strong> CUDA Programming</a></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">2.1.</strong> CUDA Concepts</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="cuda/concepts/thread_coarsening.html" target="_parent"><strong aria-hidden="true">2.1.1.</strong> Thread Coarsening</a></li><li class="chapter-item expanded "><a href="cuda/concepts/reduction.html" target="_parent"><strong aria-hidden="true">2.1.2.</strong> Reduction</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">2.2.</strong> CUDA Kernels</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="cuda/kernels/attention_forward.html" target="_parent"><strong aria-hidden="true">2.2.1.</strong> Attention</a></li><li class="chapter-item expanded "><a href="cuda/kernels/encoder_forward.html" target="_parent"><strong aria-hidden="true">2.2.2.</strong> Encoder</a></li><li class="chapter-item expanded "><a href="cuda/kernels/layernorm_forward.html" target="_parent"><strong aria-hidden="true">2.2.3.</strong> LayerNorm</a></li><li class="chapter-item expanded "><a href="cuda/kernels/matmul_forward.html" target="_parent"><strong aria-hidden="true">2.2.4.</strong> Matrix Multiplication (MatMul)</a></li><li class="chapter-item expanded "><a href="cuda/kernels/softmax_forward.html" target="_parent"><strong aria-hidden="true">2.2.5.</strong> Softmax</a></li><li class="chapter-item expanded "><a href="cuda/kernels/trimat_forward.html" target="_parent"><strong aria-hidden="true">2.2.6.</strong> Triangular Matrix Multiplication (TriMat)</a></li></ol></li></ol></li></ol>
    </body>
</html>
